{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import credentials\n",
    "import requests\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from pandas import DataFrame\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "import datetime as dt\n",
    "#pulling data API\n",
    "\n",
    "key =credentials.login['key_isaham']  # extract password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looping through all stocks\n",
    "\n",
    "def strategy_label(wl):\n",
    "    \n",
    "    ori_data = {}\n",
    "    all_ori_stocks = []\n",
    "    # Scale dictionary of dataframes for training set(scaling by stock)\n",
    "    ss={}\n",
    "    d = {}\n",
    "\n",
    "    # Scale dictionary of dataframes for prediction set(scaling by stock)\n",
    "    sp={}\n",
    "    nsp={}\n",
    "\n",
    "    for m,stock in enumerate (wl):\n",
    "\n",
    "        print(\"----------------PROCESSING {}------------------\".format(stock))\n",
    "        symbol = stock    # Which stock to pull    \n",
    "        response = requests.get(\"https://admin.isaham.my/api/chart?stock={}&key={}\".format(symbol,key))\n",
    "        data = response.json()\n",
    "\n",
    "        ori = pd.DataFrame.from_dict(data)\n",
    "        ori = ori[['c','d','h','l','o','v']]\n",
    "        ori['d'] = pd.to_datetime(ori['d'], dayfirst= True )\n",
    "        # adding the stock names\n",
    "        ori[\"Stock\"] = stock\n",
    "        ori_data[f\"{symbol}\"] = ori\n",
    "        all_ori_stocks.append(ori_data[stock])\n",
    "        \n",
    "        df = ori.reset_index(drop=False)\n",
    "        \n",
    "        \n",
    "        # Tuning OB and OS level\n",
    "        ob_cross=85\n",
    "        os_cross=35\n",
    "        \n",
    "        # Identify MA50\n",
    "        n=50\n",
    "        ma50=[] \n",
    "\n",
    "        for i in range(len(df[\"c\"])-(n-1)):\n",
    "            ma = round(sum(df[\"c\"][i:i+(n)])/n,4)\n",
    "            ma50.append(ma)\n",
    "\n",
    "        df[\"MA50\"] = pd.Series(ma50)\n",
    "        df[\"MA50\"] = df[\"MA50\"].shift(n-1)\n",
    "\n",
    "        # Filter uptrend price above ma50\n",
    "        # Calculating the gap of both MA\n",
    "        df[\"MAgap\"] = df[\"c\"] -  df[\"MA50\"] \n",
    "\n",
    "        # Set date as index\n",
    "        df.set_index('d',inplace=True,drop=False)\n",
    "        df.index.name = None\n",
    "\n",
    "        # Create signal for uptrend price above ma50 \n",
    "        # Result not accurate for stochastic when just filter uptrend only\n",
    "        df[\"Uptrend\"]=df['MAgap']>0\n",
    "        Uptrend=df[\"Uptrend\"]\n",
    "        Uptrend_signal=Uptrend[Uptrend==True]\n",
    "\n",
    "        # Signal stochastic\n",
    "        # Create the \"L14\" column in the DataFrame\n",
    "        df['L14'] = df['l'].rolling(window=14).min()\n",
    "\n",
    "        # Create the \"H14\" column in the DataFrame\n",
    "        df['H14'] = df['h'].rolling(window=14).max()\n",
    "\n",
    "        # Create the \"%K\" column in the DataFrame\n",
    "        df['%K'] = 100*((df['c'] - df['L14']) / (df['H14'] - df['L14']) )\n",
    "\n",
    "        # Create the \"%D\" column in the DataFrame\n",
    "        df['%D'] = df['%K'].rolling(window=3).mean()\n",
    "\n",
    "        # Create a column in the DataFrame showing \"TRUE\" if buy entry signal is given and \"FALSE\" otherwise. \n",
    "        # A buy is initiated when the %K line crosses up through the %D line and the value of the oscillator is below 20 \n",
    "        df['Buy OS'] = ((df['%K'] > df['%D']) & (df['%K'].shift(1) < df['%D'].shift(1))) & (df['%D'] < os_cross) & (Uptrend_signal)\n",
    "\n",
    "        # Create a column in the DataFrame showing \"TRUE\" if sell entry signal is given and \"FALSE\" otherwise. \n",
    "        # A sell is initiated when the %K line crosses down through the %D line and the value of the oscillator is above 80 \n",
    "        df['Sell OB'] = ((df['%K'] < df['%D']) & (df['%K'].shift(1) > df['%D'].shift(1))) & (df['%D'] > ob_cross) \n",
    "\n",
    "        # Create a column in the DataFrame for name of stock\n",
    "        df['Stock_Name'] = symbol\n",
    "\n",
    "        # Define overbought and oversold\n",
    "        overbought =df['Sell OB']\n",
    "        oversold =df['Buy OS']\n",
    "\n",
    "        # Use index(date) for create strategy using overbought and oversold\n",
    "        date_os=list(oversold[oversold == True].index)\n",
    "        date_ob=list(overbought[overbought == True].index)\n",
    "\n",
    "        # Scaling certain features only\n",
    "        col_names_pred = ['c', 'l', 'o', 'v','h']  \n",
    "        features_pred = df[col_names_pred]\n",
    "\n",
    "        # Scaling for prediction data\n",
    "        scaler_pred = StandardScaler().fit(features_pred.values)\n",
    "        features_pred = scaler_pred.transform(features_pred.values)\n",
    "\n",
    "        # Convert the array back to a dataframe\n",
    "        dataset_pred = DataFrame(features_pred)\n",
    "\n",
    "        # Prepare prediction data that no need to scale\n",
    "        col_notscale_pred=['d','Stock_Name','Buy OS']\n",
    "        features_notscale_pred=df[col_notscale_pred]\n",
    "\n",
    "        # Saving in multiple variable\n",
    "        sp[\"{}\".format(stock)] = dataset_pred\n",
    "        nsp[\"{}\".format(stock)] = features_notscale_pred\n",
    "\n",
    "        # Transaction recording\n",
    "        buy = []\n",
    "        sell = []\n",
    "        sdate = []\n",
    "        bdate = []\n",
    "        wr = []\n",
    "        pct = []\n",
    "        vol = []\n",
    "        ope =[]\n",
    "        high = []\n",
    "        low = []\n",
    "\n",
    "        # Record close,open,vol,high,low for buy transaction\n",
    "        for n,i in enumerate(date_os):\n",
    "            buy.append(df['c'].loc[i])\n",
    "            vol.append(df['v'].loc[i])\n",
    "            ope.append(df['o'].loc[i])\n",
    "            high.append(df['h'].loc[i])\n",
    "            low.append(df['l'].loc[i])\n",
    "            bdate.append(i)\n",
    "            r=[]\n",
    "\n",
    "            for m,k in enumerate(date_ob):\n",
    "\n",
    "                if k>i:\n",
    "                    r.append(m)\n",
    "                    if len(r) ==1:\n",
    "                        # Record close,percentage change for sell transaction\n",
    "                        sell.append(df['c'].loc[k])\n",
    "                        sdate.append(k)\n",
    "                        pct_change=((df['c'].loc[k]/df['c'].loc[i])-1)*100\n",
    "                        pct.append(((df['c'].loc[k]/df['c'].loc[i])-1)*100)\n",
    "                    elif len(r)>1:\n",
    "                        pass\n",
    "        diff =len(buy)-len(sell)\n",
    "        # Checking for final transaction, make sure it is sell, as we want to close the position\n",
    "        if len(buy) == len(sell):\n",
    "            pass   \n",
    "        elif len(buy) != len(sell):\n",
    "            # Deleting excess buy transaction after we close position\n",
    "            del(buy[-diff:])\n",
    "            del(bdate[-diff:])\n",
    "            del(ope[-diff:])\n",
    "            del(high[-diff:])\n",
    "            del(vol[-diff:])\n",
    "            del(low[-diff:])\n",
    "\n",
    "        dct = {\n",
    "            \"Buy_Date\": bdate,\n",
    "            \"Buy\": buy,\n",
    "            \"Sell\": sell,\n",
    "            \"Sell_Date\": sdate,\n",
    "            \"Open\":ope,\n",
    "            'Volume': vol,\n",
    "            \"Low\": low,\n",
    "            \"high\": high,\n",
    "            \"Pct_change\": pct    \n",
    "        }  \n",
    "\n",
    "        # Save document for stochastic strategy\n",
    "        trans = pd.DataFrame(dct)\n",
    "\n",
    "        # Define variable for winning rate\n",
    "        wr = []\n",
    "        for i in range(len(trans)):\n",
    "            if trans[\"Pct_change\"][i] > 0:\n",
    "                wr.append(1)\n",
    "            else:\n",
    "                wr.append(0)\n",
    "\n",
    "        # Define variable for name of stock\n",
    "        Name_stock = []\n",
    "        for s in range(len(trans)):\n",
    "            Name_stock.append(symbol)\n",
    "\n",
    "        # Add new column\n",
    "        trans[\"wr\"] = pd.Series(wr)\n",
    "        trans['Stock'] = pd.Series(Name_stock)\n",
    "\n",
    "        # Scaling certain features only for training data\n",
    "        col_names = ['Buy', 'Low', 'Open', 'Volume','high']  \n",
    "        features = trans[col_names]\n",
    "\n",
    "        # Prepare prediction data that no need to scale\n",
    "        scaler = StandardScaler().fit(features.values)\n",
    "        features = scaler.transform(features.values)\n",
    "\n",
    "        # Convert the array back to a dataframe\n",
    "        dataset = DataFrame(features)    \n",
    "        col_notscale = ['Buy_Date','Stock','wr']\n",
    "        features_notscale = trans[col_notscale]\n",
    "\n",
    "        # Saving in multiple variable\n",
    "        d[\"{}\".format(stock)] = dataset\n",
    "        ss[\"{}\".format(stock)] = features_notscale\n",
    "        print(\"----------------DONE {}------------------\".format(symbol))\n",
    "\n",
    "    # Combining all training data generated\n",
    "    df_notscale = pd.concat(list(ss.values()),ignore_index=True)\n",
    "    df_scale = pd.concat(list(d.values()),ignore_index=True)\n",
    "    df_scale = df_scale.rename(columns={0: 'Buy', 1: 'Low',2: 'Open', 3: 'Volume',4: 'High'})\n",
    "    result_scaler = pd.concat([df_notscale, df_scale], axis=1)\n",
    "\n",
    "    # Setting Dates as index\n",
    "    df_all = result_scaler.sort_values(by=\"Buy_Date\")\n",
    "    df_all.set_index('Buy_Date', inplace=True)\n",
    "    original = pd.concat(all_ori_stocks)\n",
    "    \n",
    "    print('############################### DONE STRATEGY LABEL ##############################')\n",
    "    \n",
    "    return df_all\n",
    "    #return(original, df_all, nsp, sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(df):\n",
    "    # Encoding the stock names\n",
    "    le = LabelEncoder()\n",
    "    df[\"Stock\"] = le.fit_transform(df[\"Stock\"])\n",
    "\n",
    "    # Define the splitting date (for training we use 2 years data)\n",
    "    # Splitting train test\n",
    "    day = dt.datetime.today().day\n",
    "    month = dt.datetime.today().month\n",
    "    year = dt.datetime.today().year - 5\n",
    "    date1 = \"{}-{}-01\".format(year, str(month).zfill(2), str(day).zfill(2))\n",
    "    date2 = str(dt.datetime.today().date())  # until yesterday only\n",
    "\n",
    "    # Separate input features and target\n",
    "    X = df.drop(['wr'], axis=1)\n",
    "    y = df.wr\n",
    "    \n",
    "    # Splitting train test\n",
    "    X_train, y_train = X[date1: date2], y[date1: date2]\n",
    "    X_trainss, y_train = X_train.to_numpy(), y_train.to_numpy()\n",
    "    \n",
    "    print('############################## DONE DATA PREP #################################')\n",
    "\n",
    "    return(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_forward(X,y,df_all):\n",
    "    start_y = 16  \n",
    "    end_y = 21\n",
    "\n",
    "    test_prec = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    for i in range((end_y + 1) - start_y):  # years remaining\n",
    "        for j in range(1,12,1):  # iteratting from 1 - 12\n",
    "\n",
    "            # Fill the string with zeros until it is 2 characters long  \n",
    "            date1 = \"20{}-{}-01\".format(start_y + i, str(j).zfill(2))  # starting of the test set\n",
    "            date2 = \"20{}-{}-01\".format(start_y + i, str(j + 2).zfill(2))  # contain in 1 month only\n",
    "\n",
    "            if j == 11:\n",
    "                date2 = \"20{}-{}-01\".format(start_y + (i + 1), str((j + 2) - j).zfill(2))  # contain in 1 month only\n",
    "\n",
    "            if date2 < str(df_all.index[-1]):  # limiting the splitting for duration below the last date\n",
    "\n",
    "                #print(\"Start:\", date1)\n",
    "                #print(\"End:\", date2)\n",
    "\n",
    "                # splitting train test\n",
    "                X_train, y_train = X[:date1], y[:date1]\n",
    "                X_test, y_test = X[date1:date2], y[date1:date2]\n",
    "                #print(\"#### {}, {} ####\".format(len(X_train), len(X_test)))\n",
    "\n",
    "\n",
    "\n",
    "                # defining the model\n",
    "                model = XGBClassifier(verbosity=0)\n",
    "                # training the model\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # predicting the train and test set\n",
    "                # train\n",
    "                y_pred = model.predict(X_train)\n",
    "                pred1 = [round(value) for value in y_pred]\n",
    "                train_accuracy = accuracy_score(y_train, pred1)\n",
    "                train_acc.append(train_accuracy)\n",
    "\n",
    "                # test\n",
    "                y_pred = model.predict(X_test)\n",
    "                pred2 = [round(value) for value in y_pred]\n",
    "                test_accuracy = accuracy_score(y_test, pred2)\n",
    "                test_acc.append(test_accuracy)\n",
    "                #print(\"Test Accuracy: %.2f%%\" % (test_accuracy * 100.0))\n",
    "\n",
    "                precision = precision_score(y_test, pred2)\n",
    "                test_prec.append(precision)\n",
    "                #print(\"Test Precision: %.2f%%\" % (precision * 100.0))\n",
    "\n",
    "                #if i == 0:\n",
    "                    #print(\"----------------------------- DONE ROUND {} -----------------------------\".format(i*10 + j))\n",
    "                #else:\n",
    "                    #print(\"----------------------------- DONE ROUND {} ----------------------------- \\n\".format(i*10 + j+(2*i)))\n",
    "    # remove nan values for list test_acc\n",
    "    new_test_acc = [x for x in test_acc if np.isnan(x) == False]\n",
    "    avg_1 = sum(train_acc)/len(train_acc)  # calculating the average accuracy of the train set\n",
    "    avg_2 = round(sum(new_test_acc)/len(new_test_acc),4)  # calculating the average accuracy of the test set\n",
    "    print(\"Overall Train accuracy is: {}\".format(avg_1))\n",
    "    print(\"Overall Test accuracy is: {}\".format(avg_2)) \n",
    "\n",
    "    avg_3 = sum(test_prec)/len(test_prec)  # calculating the average accuracy of the train set\n",
    "    print(\"Overall Test precision is: {}\".format(avg_3))\n",
    "    return avg_3\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sector_filter(sector):\n",
    "\n",
    "  # pulling data from api\n",
    "  URL = 'https://admin.isaham.my/api/stocks/list'\n",
    "  r = requests.get(url = URL) \n",
    "  data = r.json() \n",
    "  df = pd.DataFrame(data['stocks'],columns = ['code','symbol','name','primary-sector','secondary-sector'])\n",
    "\n",
    "  wl = df[df[\"primary-sector\"]==sector]\n",
    "  wl = list(wl.symbol)\n",
    "\n",
    "  return(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(wl):\n",
    "    df_all=strategy_label(wl)\n",
    "    X,y=data_prep(df_all)\n",
    "    avg_3=walk_forward(X,y,df_all)\n",
    "    \n",
    "    return X,y,df_all,avg_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology:\n",
      "----------------PROCESSING WILLOW------------------\n",
      "----------------DONE WILLOW------------------\n",
      "----------------PROCESSING LAMBO------------------\n",
      "----------------DONE LAMBO------------------\n",
      "----------------PROCESSING NETX------------------\n",
      "----------------DONE NETX------------------\n",
      "----------------PROCESSING GHLSYS------------------\n",
      "----------------DONE GHLSYS------------------\n",
      "----------------PROCESSING IFCAMSC------------------\n",
      "----------------DONE IFCAMSC------------------\n",
      "----------------PROCESSING NOVAMSC------------------\n",
      "----------------DONE NOVAMSC------------------\n",
      "----------------PROCESSING DIGISTA------------------\n",
      "----------------DONE DIGISTA------------------\n",
      "----------------PROCESSING MMAG------------------\n",
      "----------------DONE MMAG------------------\n",
      "----------------PROCESSING KGROUP------------------\n",
      "----------------DONE KGROUP------------------\n",
      "----------------PROCESSING OPENSYS------------------\n",
      "----------------DONE OPENSYS------------------\n",
      "----------------PROCESSING HONGSENG------------------\n",
      "----------------DONE HONGSENG------------------\n",
      "----------------PROCESSING SYSTECH------------------\n",
      "----------------DONE SYSTECH------------------\n",
      "----------------PROCESSING CUSCAPI------------------\n",
      "----------------DONE CUSCAPI------------------\n",
      "----------------PROCESSING GRANFLO------------------\n",
      "----------------DONE GRANFLO------------------\n",
      "----------------PROCESSING VC------------------\n",
      "----------------DONE VC------------------\n",
      "----------------PROCESSING EFORCE------------------\n",
      "----------------DONE EFORCE------------------\n",
      "----------------PROCESSING ASDION------------------\n",
      "----------------DONE ASDION------------------\n",
      "----------------PROCESSING VIVOCOM------------------\n",
      "----------------DONE VIVOCOM------------------\n",
      "----------------PROCESSING MQTECH------------------\n",
      "----------------DONE MQTECH------------------\n",
      "----------------PROCESSING ORION------------------\n",
      "----------------DONE ORION------------------\n",
      "----------------PROCESSING NOTION------------------\n",
      "----------------DONE NOTION------------------\n",
      "----------------PROCESSING MLAB------------------\n",
      "----------------DONE MLAB------------------\n",
      "----------------PROCESSING YGL------------------\n",
      "----------------DONE YGL------------------\n",
      "----------------PROCESSING ELSOFT------------------\n",
      "----------------DONE ELSOFT------------------\n",
      "----------------PROCESSING SOLUTN------------------\n",
      "----------------DONE SOLUTN------------------\n",
      "----------------PROCESSING INIX------------------\n",
      "----------------DONE INIX------------------\n",
      "----------------PROCESSING VITROX------------------\n",
      "----------------DONE VITROX------------------\n",
      "----------------PROCESSING GENETEC------------------\n",
      "----------------DONE GENETEC------------------\n",
      "----------------PROCESSING REXIT------------------\n",
      "----------------DONE REXIT------------------\n",
      "----------------PROCESSING EDUSPEC------------------\n",
      "----------------DONE EDUSPEC------------------\n",
      "----------------PROCESSING N2N------------------\n",
      "----------------DONE N2N------------------\n",
      "----------------PROCESSING K1------------------\n",
      "----------------DONE K1------------------\n",
      "----------------PROCESSING MIKROMB------------------\n",
      "----------------DONE MIKROMB------------------\n",
      "----------------PROCESSING MMSV------------------\n",
      "----------------DONE MMSV------------------\n",
      "----------------PROCESSING SMRT------------------\n",
      "----------------DONE SMRT------------------\n",
      "----------------PROCESSING TRIVE------------------\n",
      "----------------DONE TRIVE------------------\n",
      "----------------PROCESSING APPASIA------------------\n",
      "----------------DONE APPASIA------------------\n",
      "----------------PROCESSING VIS------------------\n",
      "----------------DONE VIS------------------\n",
      "----------------PROCESSING MICROLN------------------\n",
      "----------------DONE MICROLN------------------\n",
      "----------------PROCESSING JHM------------------\n",
      "----------------DONE JHM------------------\n",
      "----------------PROCESSING FRONTKN------------------\n",
      "----------------DONE FRONTKN------------------\n",
      "----------------PROCESSING DGSB------------------\n",
      "----------------DONE DGSB------------------\n",
      "----------------PROCESSING TDEX------------------\n",
      "----------------DONE TDEX------------------\n",
      "----------------PROCESSING MYEG------------------\n",
      "----------------DONE MYEG------------------\n",
      "----------------PROCESSING KEYASIC------------------\n",
      "----------------DONE KEYASIC------------------\n",
      "----------------PROCESSING TFP------------------\n",
      "----------------DONE TFP------------------\n",
      "----------------PROCESSING JFTECH------------------\n",
      "----------------DONE JFTECH------------------\n",
      "----------------PROCESSING DGB------------------\n",
      "----------------DONE DGB------------------\n",
      "----------------PROCESSING EAH------------------\n",
      "----------------DONE EAH------------------\n",
      "----------------PROCESSING MPAY------------------\n",
      "----------------DONE MPAY------------------\n",
      "----------------PROCESSING INARI------------------\n",
      "----------------DONE INARI------------------\n",
      "----------------PROCESSING SMTRACK------------------\n",
      "----------------DONE SMTRACK------------------\n",
      "----------------PROCESSING IDMENSN------------------\n",
      "----------------DONE IDMENSN------------------\n",
      "----------------PROCESSING KRONO------------------\n",
      "----------------DONE KRONO------------------\n",
      "----------------PROCESSING AEMULUS------------------\n",
      "----------------DONE AEMULUS------------------\n",
      "----------------PROCESSING REVENUE------------------\n",
      "----------------DONE REVENUE------------------\n",
      "----------------PROCESSING RGTECH------------------\n",
      "----------------DONE RGTECH------------------\n",
      "----------------PROCESSING GREATEC------------------\n",
      "----------------DONE GREATEC------------------\n",
      "----------------PROCESSING MPI------------------\n",
      "----------------DONE MPI------------------\n",
      "----------------PROCESSING TURIYA------------------\n",
      "----------------DONE TURIYA------------------\n",
      "----------------PROCESSING DNEX------------------\n",
      "----------------DONE DNEX------------------\n",
      "----------------PROCESSING UNISEM------------------\n",
      "----------------DONE UNISEM------------------\n",
      "----------------PROCESSING MSNIAGA------------------\n",
      "----------------DONE MSNIAGA------------------\n",
      "----------------PROCESSING HTPADU------------------\n",
      "----------------DONE HTPADU------------------\n",
      "----------------PROCESSING EDARAN------------------\n",
      "----------------DONE EDARAN------------------\n",
      "----------------PROCESSING JCY------------------\n",
      "----------------DONE JCY------------------\n",
      "----------------PROCESSING VSTECS------------------\n",
      "----------------DONE VSTECS------------------\n",
      "----------------PROCESSING CENSOF------------------\n",
      "----------------DONE CENSOF------------------\n",
      "----------------PROCESSING AWANTEC------------------\n",
      "----------------DONE AWANTEC------------------\n",
      "----------------PROCESSING DSONIC------------------\n",
      "----------------DONE DSONIC------------------\n",
      "----------------PROCESSING GLOTEC------------------\n",
      "----------------DONE GLOTEC------------------\n",
      "----------------PROCESSING MI------------------\n",
      "----------------DONE MI------------------\n",
      "----------------PROCESSING UWC------------------\n",
      "----------------DONE UWC------------------\n",
      "----------------PROCESSING GTRONIC------------------\n",
      "----------------DONE GTRONIC------------------\n",
      "----------------PROCESSING DNONCE------------------\n",
      "----------------DONE DNONCE------------------\n",
      "----------------PROCESSING DPHARMA------------------\n",
      "----------------DONE DPHARMA------------------\n",
      "----------------PROCESSING PENTA------------------\n",
      "----------------DONE PENTA------------------\n",
      "----------------PROCESSING ARBB------------------\n",
      "----------------DONE ARBB------------------\n",
      "----------------PROCESSING G3------------------\n",
      "----------------DONE G3------------------\n",
      "----------------PROCESSING D&O------------------\n",
      "----------------DONE D&O------------------\n",
      "----------------PROCESSING DATAPRP------------------\n",
      "----------------DONE DATAPRP------------------\n",
      "----------------PROCESSING OMESTI------------------\n",
      "----------------DONE OMESTI------------------\n",
      "----------------PROCESSING THETA------------------\n",
      "----------------DONE THETA------------------\n",
      "----------------PROCESSING KESM------------------\n",
      "----------------DONE KESM------------------\n",
      "----------------PROCESSING FSBM------------------\n",
      "----------------DONE FSBM------------------\n",
      "----------------PROCESSING ITRONIC------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------DONE ITRONIC------------------\n",
      "############################### DONE STRATEGY LABEL ##############################\n",
      "############################## DONE DATA PREP #################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Train accuracy is: 0.9140832056878221\n",
      "Overall Test accuracy is: 0.5717\n",
      "Overall Test precision is: 0.565087218285991\n",
      "Healthcare:\n",
      "----------------PROCESSING SCOMNET------------------\n",
      "----------------DONE SCOMNET------------------\n",
      "----------------PROCESSING KOTRA------------------\n",
      "----------------DONE KOTRA------------------\n",
      "----------------PROCESSING LYC------------------\n",
      "----------------DONE LYC------------------\n",
      "----------------PROCESSING TMCLIFE------------------\n",
      "----------------DONE TMCLIFE------------------\n",
      "----------------PROCESSING MGRC------------------\n",
      "----------------DONE MGRC------------------\n",
      "----------------PROCESSING CAREPLS------------------\n",
      "----------------DONE CAREPLS------------------\n",
      "----------------PROCESSING LKL------------------\n",
      "----------------DONE LKL------------------\n",
      "----------------PROCESSING TDM------------------\n",
      "----------------DONE TDM------------------\n",
      "----------------PROCESSING HARTA------------------\n",
      "----------------DONE HARTA------------------\n",
      "----------------PROCESSING IHH------------------\n",
      "----------------DONE IHH------------------\n",
      "----------------PROCESSING KPJ------------------\n",
      "----------------DONE KPJ------------------\n",
      "----------------PROCESSING PHARMA------------------\n",
      "----------------DONE PHARMA------------------\n",
      "----------------PROCESSING AHEALTH------------------\n",
      "----------------DONE AHEALTH------------------\n",
      "----------------PROCESSING SUPERMX------------------\n",
      "----------------DONE SUPERMX------------------\n",
      "----------------PROCESSING TOPGLOV------------------\n",
      "----------------DONE TOPGLOV------------------\n",
      "----------------PROCESSING KOSSAN------------------\n",
      "----------------DONE KOSSAN------------------\n",
      "----------------PROCESSING YSPSAH------------------\n",
      "----------------DONE YSPSAH------------------\n",
      "----------------PROCESSING ADVENTA------------------\n",
      "----------------DONE ADVENTA------------------\n",
      "############################### DONE STRATEGY LABEL ##############################\n",
      "############################## DONE DATA PREP #################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Public\\Documents\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Train accuracy is: 0.9836516037992673\n",
      "Overall Test accuracy is: 0.5808\n",
      "Overall Test precision is: 0.6253838553885548\n",
      "Construction:\n",
      "----------------PROCESSING SCBUILD------------------\n",
      "----------------DONE SCBUILD------------------\n",
      "----------------PROCESSING WIDAD------------------\n",
      "----------------DONE WIDAD------------------\n",
      "----------------PROCESSING INTA------------------\n",
      "----------------DONE INTA------------------\n",
      "----------------PROCESSING GDB------------------\n",
      "----------------DONE GDB------------------\n",
      "----------------PROCESSING NADIBHD------------------\n",
      "----------------DONE NADIBHD------------------\n",
      "----------------PROCESSING TCS------------------\n",
      "----------------DONE TCS------------------\n",
      "----------------PROCESSING MRCB------------------\n",
      "----------------DONE MRCB------------------\n",
      "----------------PROCESSING ZELAN------------------\n",
      "----------------DONE ZELAN------------------\n",
      "----------------PROCESSING GKENT------------------\n",
      "----------------DONE GKENT------------------\n",
      "----------------PROCESSING IJM------------------\n",
      "----------------DONE IJM------------------\n",
      "----------------PROCESSING WCEHB------------------\n",
      "----------------DONE WCEHB------------------\n",
      "----------------PROCESSING JAKS------------------\n",
      "----------------DONE JAKS------------------\n",
      "----------------PROCESSING STELLA------------------\n",
      "----------------DONE STELLA------------------\n",
      "----------------PROCESSING TSRCAP------------------\n",
      "----------------DONE TSRCAP------------------\n",
      "----------------PROCESSING TRC------------------\n",
      "----------------DONE TRC------------------\n",
      "----------------PROCESSING PRTASCO------------------\n",
      "----------------DONE PRTASCO------------------\n",
      "----------------PROCESSING MUDAJYA------------------\n",
      "----------------DONE MUDAJYA------------------\n",
      "----------------PROCESSING MELATI------------------\n",
      "----------------DONE MELATI------------------\n",
      "----------------PROCESSING HOHUP------------------\n",
      "----------------DONE HOHUP------------------\n",
      "----------------PROCESSING KIMLUN------------------\n",
      "----------------DONE KIMLUN------------------\n",
      "----------------PROCESSING DYNACIA------------------\n",
      "----------------DONE DYNACIA------------------\n",
      "----------------PROCESSING BENALEC------------------\n",
      "----------------DONE BENALEC------------------\n",
      "----------------PROCESSING SENDAI------------------\n",
      "----------------DONE SENDAI------------------\n",
      "----------------PROCESSING GBGAQRS------------------\n",
      "----------------DONE GBGAQRS------------------\n",
      "----------------PROCESSING ECONBHD------------------\n",
      "----------------DONE ECONBHD------------------\n",
      "----------------PROCESSING SUNCON------------------\n",
      "----------------DONE SUNCON------------------\n",
      "----------------PROCESSING TOPBLDS------------------\n",
      "----------------DONE TOPBLDS------------------\n",
      "----------------PROCESSING ADVCON------------------\n",
      "----------------DONE ADVCON------------------\n",
      "----------------PROCESSING AME------------------\n",
      "----------------DONE AME------------------\n",
      "----------------PROCESSING GAMUDA------------------\n",
      "----------------DONE GAMUDA------------------\n",
      "----------------PROCESSING PEB------------------\n",
      "----------------DONE PEB------------------\n",
      "----------------PROCESSING MUHIBAH------------------\n",
      "----------------DONE MUHIBAH------------------\n",
      "----------------PROCESSING MTDACPI------------------\n",
      "----------------DONE MTDACPI------------------\n",
      "----------------PROCESSING BPURI------------------\n",
      "----------------DONE BPURI------------------\n",
      "----------------PROCESSING HSL------------------\n",
      "----------------DONE HSL------------------\n",
      "----------------PROCESSING PUNCAK------------------\n",
      "----------------DONE PUNCAK------------------\n",
      "----------------PROCESSING ZECON------------------\n",
      "----------------DONE ZECON------------------\n",
      "----------------PROCESSING FAJAR------------------\n",
      "----------------DONE FAJAR------------------\n",
      "----------------PROCESSING VIZIONE------------------\n",
      "----------------DONE VIZIONE------------------\n",
      "----------------PROCESSING OCR------------------\n",
      "----------------DONE OCR------------------\n",
      "----------------PROCESSING AZRB------------------\n",
      "----------------DONE AZRB------------------\n",
      "----------------PROCESSING AGES------------------\n",
      "----------------DONE AGES------------------\n",
      "----------------PROCESSING KERJAYA------------------\n",
      "----------------DONE KERJAYA------------------\n",
      "----------------PROCESSING WZSATU------------------\n",
      "----------------DONE WZSATU------------------\n",
      "----------------PROCESSING DKLS------------------\n",
      "----------------DONE DKLS------------------\n",
      "----------------PROCESSING PESONA------------------\n",
      "----------------DONE PESONA------------------\n",
      "----------------PROCESSING CRESBLD------------------\n",
      "----------------DONE CRESBLD------------------\n",
      "----------------PROCESSING BREM------------------\n",
      "----------------DONE BREM------------------\n",
      "----------------PROCESSING IREKA------------------\n",
      "----------------DONE IREKA------------------\n",
      "----------------PROCESSING EKOVEST------------------\n",
      "----------------DONE EKOVEST------------------\n",
      "----------------PROCESSING GADANG------------------\n",
      "----------------DONE GADANG------------------\n",
      "----------------PROCESSING MITRA------------------\n",
      "----------------DONE MITRA------------------\n",
      "----------------PROCESSING PTARAS------------------\n",
      "----------------DONE PTARAS------------------\n",
      "----------------PROCESSING LEBTECH------------------\n",
      "----------------DONE LEBTECH------------------\n",
      "----------------PROCESSING WCT------------------\n",
      "----------------DONE WCT------------------\n",
      "----------------PROCESSING SYCAL------------------\n",
      "----------------DONE SYCAL------------------\n",
      "############################### DONE STRATEGY LABEL ##############################\n",
      "############################## DONE DATA PREP #################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\Documents\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\Public\\Documents\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Train accuracy is: 0.927878639336509\n",
      "Overall Test accuracy is: 0.5384\n",
      "Overall Test precision is: 0.5223442128817541\n"
     ]
    }
   ],
   "source": [
    "sectors = [\"Technology\", \"Healthcare\", \"Construction\"]\n",
    "\n",
    "\n",
    "for sector in sectors:\n",
    "    wl = sector_filter(sector)\n",
    "    print(f\"{sector}:\")\n",
    "    X,y,df_all,avg_3= precision(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
